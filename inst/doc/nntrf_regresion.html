<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Ricardo Aler" />

<meta name="date" content="2020-08-06" />

<title>nntrf for regression</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' || rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />




</head>

<body>




<h1 class="title toc-ignore">nntrf for regression</h1>
<h4 class="author">Ricardo Aler</h4>
<h4 class="date">2020-08-06</h4>



<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(nntrf)
<span class="kw">library</span>(mlr)
<span class="co">#&gt; Loading required package: ParamHelpers</span>
<span class="co">#&gt; 'mlr' is in maintenance mode since July 2019. Future development</span>
<span class="co">#&gt; efforts will go into its successor 'mlr3'</span>
<span class="co">#&gt; (&lt;https://mlr3.mlr-org.com&gt;).</span>
<span class="kw">library</span>(mlrCPO)
<span class="kw">library</span>(FNN)</code></pre></div>
<div id="overview" class="section level1">
<h1>Overview</h1>
<p>Here, <strong>nntrf</strong> is going to be applied to a simple regression problem <span class="math inline">\(y = sin(x)\)</span>, with a single relevant attribute (x). 8 random attributes will be added, and then the instances will be randomly rotated, so that none of the 10 attributes contains all the information. Then, <strong>nntrf</strong> will be used to transform this feature space and <strong>knn</strong> will be used as machine learning method on this space.</p>
<p>Let’s first create the regression data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>,<span class="dt">length.out =</span> <span class="dv">5000</span>)
y &lt;-<span class="st"> </span><span class="kw">sin</span>(x)
extra &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">runif</span>(<span class="dv">5000</span><span class="op">*</span><span class="dv">9</span>),<span class="dt">nrow =</span> <span class="dv">5000</span>)
data &lt;-<span class="st"> </span><span class="kw">cbind</span>(x, <span class="kw">as.data.frame</span>(extra), y)
<span class="kw">plot</span>(data<span class="op">$</span>x,data<span class="op">$</span>y)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>Now, let’s add 9 random attributes to the dataset, and rotate every instance with a random rotation matrix. The result is that none of the 10 attributes can now be identified with the only relevant attribute (originally, x).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">cbind</span>(x, extra))
<span class="kw">set.seed</span>(<span class="dv">0</span>)
mat_ortho &lt;-<span class="st"> </span>pracma<span class="op">::</span><span class="kw">randortho</span>(<span class="kw">ncol</span>(m), <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;orthonormal&quot;</span>))
m_p &lt;-<span class="st"> </span>m <span class="op">%*%</span><span class="st"> </span>mat_ortho
data &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">as.data.frame</span>(m_p), y)</code></pre></div>
<p>Inputs and output are normalized to the 0-1 range using mlr utilities.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span>mlr<span class="op">::</span><span class="kw">normalizeFeatures</span>(data, <span class="dt">method=</span><span class="st">&quot;range&quot;</span>)</code></pre></div>
<p>Data is now divided into train / test partitions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rd &lt;-<span class="st"> </span>data
n &lt;-<span class="st"> </span><span class="kw">nrow</span>(rd)

<span class="kw">set.seed</span>(<span class="dv">0</span>)
training_index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span>n, <span class="kw">round</span>(<span class="fl">0.6</span><span class="op">*</span>n))
  
train &lt;-<span class="st"> </span>rd[training_index,]
test &lt;-<span class="st"> </span>rd[<span class="op">-</span>training_index,]
x_train &lt;-<span class="st"> </span>train[,<span class="op">-</span><span class="kw">ncol</span>(train)]
y_train &lt;-<span class="st"> </span>train[,<span class="kw">ncol</span>(train)]
x_test &lt;-<span class="st"> </span>test[,<span class="op">-</span><span class="kw">ncol</span>(test)]
y_test &lt;-<span class="st"> </span>test[,<span class="kw">ncol</span>(test)] </code></pre></div>
<p>Now, let’s see the MAE error of the original (x,y) instances (prior to adding the random attributes and performing the random rotation). This is the best result we could expect from KNN (having fixed the number of neighbors to k=3).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">0</span>)
outputs &lt;-<span class="st"> </span>FNN<span class="op">::</span><span class="kw">knn.reg</span>(<span class="kw">as.data.frame</span>(x[training_index]), <span class="kw">as.data.frame</span>(x[<span class="op">-</span>training_index]), y_train, <span class="dt">k=</span><span class="dv">3</span>)
mae_error &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">abs</span>(outputs<span class="op">$</span>pred <span class="op">-</span><span class="st"> </span>y_test))
<span class="kw">cat</span>(<span class="kw">paste0</span>(<span class="st">&quot;MAE of KNN (K=3):&quot;</span>, mae_error, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>))
<span class="co">#&gt; MAE of KNN (K=3):0.00107947968440619</span></code></pre></div>
<p>Next, test MAE is computed with the randomized dataset (+9 random attributes and random rotation). It is much worse than the one above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">0</span>)
outputs &lt;-<span class="st"> </span>FNN<span class="op">::</span><span class="kw">knn.reg</span>(x_train, x_test, y_train, <span class="dt">k=</span><span class="dv">3</span>)
mae_error &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">abs</span>(outputs<span class="op">$</span>pred <span class="op">-</span><span class="st"> </span>y_test))
<span class="kw">cat</span>(<span class="kw">paste0</span>(<span class="st">&quot;MAE of KNN (K=3):&quot;</span>, mae_error, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>))
<span class="co">#&gt; MAE of KNN (K=3):0.117339310780657</span></code></pre></div>
<p>Next, <strong>nntrf</strong> is used to reduce the 10 dimensions to the 1 relevant dimension. It can be seen that MAE improves significantly over previous result, if no sigmoid is used in the nntrf transformation (however, it is still somewhat far away from the optimal result).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">0</span>)
nnpo &lt;-<span class="st"> </span><span class="kw">nntrf</span>(<span class="dt">formula=</span>y<span class="op">~</span>.,
              <span class="dt">data=</span>train,
              <span class="dt">size=</span><span class="dv">1</span>, <span class="dt">maxit=</span><span class="dv">500</span>, <span class="dt">trace=</span><span class="ot">FALSE</span>, <span class="dt">repetitions=</span><span class="dv">2</span>)

<span class="co"># With sigmoid</span>

trf_x_train &lt;-<span class="st"> </span>nnpo<span class="op">$</span><span class="kw">trf</span>(<span class="dt">x=</span>x_train,<span class="dt">use_sigmoid=</span><span class="ot">TRUE</span>)
trf_x_test &lt;-<span class="st"> </span>nnpo<span class="op">$</span><span class="kw">trf</span>(<span class="dt">x=</span>x_test,<span class="dt">use_sigmoid=</span><span class="ot">TRUE</span>)

outputs &lt;-<span class="st"> </span>FNN<span class="op">::</span><span class="kw">knn.reg</span>(trf_x_train, trf_x_test, y_train, <span class="dt">k =</span> <span class="dv">3</span>)
mae &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">abs</span>(outputs<span class="op">$</span>pred <span class="op">-</span><span class="st"> </span>y_test))
<span class="kw">cat</span>(<span class="kw">paste0</span>(<span class="st">&quot;MAE of KNN (K=3) transformed by nntrf with Sigmoid: &quot;</span>, mae, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>))
<span class="co">#&gt; MAE of KNN (K=3) transformed by nntrf with Sigmoid: 0.215157453152229</span>

<span class="co"># With no sigmoid</span>
trf_x_train &lt;-<span class="st"> </span>nnpo<span class="op">$</span><span class="kw">trf</span>(<span class="dt">x=</span>x_train,<span class="dt">use_sigmoid=</span><span class="ot">FALSE</span>)
trf_x_test &lt;-<span class="st"> </span>nnpo<span class="op">$</span><span class="kw">trf</span>(<span class="dt">x=</span>x_test,<span class="dt">use_sigmoid=</span><span class="ot">FALSE</span>)

outputs &lt;-<span class="st"> </span>FNN<span class="op">::</span><span class="kw">knn.reg</span>(trf_x_train, trf_x_test, y_train, <span class="dt">k=</span><span class="dv">3</span>)
mae &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">abs</span>(outputs<span class="op">$</span>pred <span class="op">-</span><span class="st"> </span>y_test))
<span class="kw">cat</span>(<span class="kw">paste0</span>(<span class="st">&quot;MAE of KNN (K=3) transformed by nntrf with no sigmoid: &quot;</span>, mae, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>))
<span class="co">#&gt; MAE of KNN (K=3) transformed by nntrf with no sigmoid: 0.00690412204721888</span></code></pre></div>
<p>It can be seen that the sine shape was restored.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(trf_x_test[,<span class="dv">1</span>], y_test)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>Now, let’s use hyper-parameter tuning, with 3-fold crossvalidation for model evaluation and 3-fold crossvalidation for hyper-parameter tuning.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sin_task &lt;-<span class="st"> </span><span class="kw">makeRegrTask</span>(<span class="dt">data=</span>data, <span class="dt">target=</span><span class="st">&quot;y&quot;</span>)

control_grid &lt;-<span class="st"> </span><span class="kw">makeTuneControlGrid</span>()
inner_desc &lt;-<span class="st"> </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iter=</span><span class="dv">3</span>)
outer_desc &lt;-<span class="st">  </span><span class="kw">makeResampleDesc</span>(<span class="st">&quot;CV&quot;</span>, <span class="dt">iter=</span><span class="dv">3</span>)
<span class="kw">set.seed</span>(<span class="dv">0</span>)
outer_inst &lt;-<span class="st"> </span><span class="kw">makeResampleInstance</span>(outer_desc, sin_task)</code></pre></div>
<p>What follows is the definition of nntrf as a pre-processing stage for mlr. It can be just copied.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cpo_nntrf =<span class="st"> </span><span class="kw">makeCPO</span>(<span class="st">&quot;nntrfCPO&quot;</span>,  
                       <span class="co"># Here, the hyper-parameters of nntrf are defined</span>
                       <span class="kw">pSS</span>(<span class="dt">repetitions =</span> <span class="dv">1</span> <span class="op">:</span><span class="st"> </span>integer[<span class="dv">1</span>, ],
                           size<span class="op">:</span><span class="st"> </span>integer[<span class="dv">1</span>, ],
                           <span class="dt">maxit =</span> <span class="dv">100</span> <span class="op">:</span><span class="st"> </span>integer[<span class="dv">1</span>, ],
                           <span class="dt">use_sigmoid =</span> <span class="ot">FALSE</span><span class="op">:</span><span class="st"> </span>logical),
                       <span class="dt">dataformat =</span> <span class="st">&quot;numeric&quot;</span>,
                       <span class="dt">cpo.train =</span> <span class="cf">function</span>(data, target, 
                                            repetitions, 
                                            size, maxit, use_sigmoid) {
                         data_and_class &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">as.data.frame</span>(data), <span class="dt">class=</span>target[[<span class="dv">1</span>]])
                         nnpo &lt;-<span class="st"> </span><span class="kw">nntrf</span>(<span class="dt">repetitions=</span>repetitions,
                                       <span class="dt">formula=</span>class<span class="op">~</span>.,
                                       <span class="dt">data=</span>data_and_class,
                                       <span class="dt">size=</span>size, <span class="dt">maxit=</span>maxit, <span class="dt">trace=</span><span class="ot">FALSE</span>)
                       },
                       <span class="dt">cpo.retrafo =</span> <span class="cf">function</span>(data, control, 
                                              repetitions, 
                                              size, maxit, use_sigmoid) {
                       
                         trf_x &lt;-<span class="st"> </span>control<span class="op">$</span><span class="kw">trf</span>(<span class="dt">x=</span>data,<span class="dt">use_sigmoid=</span>use_sigmoid)
                         trf_x
                       })</code></pre></div>
<p>Next, the pipeline of pre-processing + classifier method (KNN in this case) is defined.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># knn is the machine learning method. The knn available in the FNN package is used</span>
knn_lrn &lt;-<span class="st"> </span><span class="kw">makeLearner</span>(<span class="st">&quot;regr.fnn&quot;</span>)
<span class="co"># Then, knn is combined with nntrf's preprocessing into a pipeline</span>
knn_nntrf &lt;-<span class="st"> </span><span class="kw">cpo_nntrf</span>() <span class="op">%&gt;&gt;%</span><span class="st"> </span>knn_lrn
<span class="co"># Just in case, we fix the values of the hyper-parameters that we do not require to optimize</span>
<span class="co"># (not necessary, because they already have default values. Just to make their values explicit)</span>
knn_nntrf &lt;-<span class="st"> </span><span class="kw">setHyperPars</span>(knn_nntrf, <span class="dt">nntrfCPO.repetitions=</span><span class="dv">1</span>, <span class="dt">nntrfCPO.maxit=</span><span class="dv">100</span>,
                          <span class="dt">nntrfCPO.use_sigmoid=</span><span class="ot">FALSE</span>)

<span class="co"># However, we are going to use 2 repetitions here, instead of 1 (the default):</span>

knn_nntrf &lt;-<span class="st"> </span><span class="kw">setHyperPars</span>(knn_nntrf, <span class="dt">nntrfCPO.repetitions=</span><span class="dv">2</span>)</code></pre></div>
<p>Next, the hyper-parameter space for the pipeline is defined. Only three hyper-parameters will be optimized: the number of KNN neighbors (k), from 1 to 7, the number of hidden neurons (size), from 1 to 5, and the number of iterations. The remaining hyper-parameters are left to some default values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ps &lt;-<span class="st"> </span><span class="kw">makeParamSet</span>(<span class="kw">makeDiscreteParam</span>(<span class="st">&quot;k&quot;</span>, <span class="dt">values =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>),
                   <span class="kw">makeDiscreteParam</span>(<span class="st">&quot;nntrfCPO.size&quot;</span>, <span class="dt">values =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>),
                   <span class="kw">makeDiscreteParam</span>(<span class="st">&quot;nntrfCPO.maxit&quot;</span>, <span class="dt">values =</span> <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>, <span class="dv">2000</span>))
)</code></pre></div>
<p>Next, a mlr wrapper is used to give the <strong>knn_nntrf</strong> pipeline the ability to do hyper-parameter tuning.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knn_nntrf_tune &lt;-<span class="st"> </span><span class="kw">makeTuneWrapper</span>(knn_nntrf, <span class="dt">resampling =</span> inner_desc, <span class="dt">par.set =</span> ps, 
                                     <span class="dt">control =</span> control_grid, <span class="dt">measures =</span> <span class="kw">list</span>(mlr<span class="op">::</span>mae), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>Finally, the complete process (3-fold hyper-parameter tuning) and 3-fold outer model evaluation is run. It takes some time.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">0</span>)
<span class="co"># Please, note that in order to save time, results have been precomputed</span>
cached &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;error_knn_nntrf_regression.rda&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;nntrf&quot;</span>)
<span class="cf">if</span>(<span class="kw">file.exists</span>(cached)){<span class="kw">load</span>(cached)} <span class="cf">else</span> {
  error_knn_nntrf_tune &lt;-<span class="st"> </span><span class="kw">resample</span>(knn_nntrf_tune, sin_task, outer_inst, 
                                   <span class="dt">measures =</span> <span class="kw">list</span>(mlr<span class="op">::</span>mae), 
                                   <span class="dt">extract =</span> getTuneResult, <span class="dt">show.info =</span>  <span class="ot">FALSE</span>)

  <span class="co"># save(error_knn_nntrf_tune, file=&quot;../inst/extdata/error_knn_nntrf_regression.rda&quot;)</span>
}</code></pre></div>
<p>Errors (<strong>mae.test.mean</strong>) and optimal hyper-parameters are printed below. It can be seen that hyper-parameter tuning is not able to detect that only 1 relevant attribute is needed, but MAE test results will show (later) that the projection carried out by <strong>nntrf</strong> achieves a good MAE result.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(error_knn_nntrf_tune<span class="op">$</span>extract)
<span class="co">#&gt; [[1]]</span>
<span class="co">#&gt; Tune result:</span>
<span class="co">#&gt; Op. pars: k=4; nntrfCPO.size=5; nntrfCPO.maxit=2000</span>
<span class="co">#&gt; mae.test.mean=0.0023038</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[2]]</span>
<span class="co">#&gt; Tune result:</span>
<span class="co">#&gt; Op. pars: k=6; nntrfCPO.size=5; nntrfCPO.maxit=500</span>
<span class="co">#&gt; mae.test.mean=0.0023746</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[3]]</span>
<span class="co">#&gt; Tune result:</span>
<span class="co">#&gt; Op. pars: k=2; nntrfCPO.size=5; nntrfCPO.maxit=500</span>
<span class="co">#&gt; mae.test.mean=0.0023567</span></code></pre></div>
<p>The final outer 3-fold crossvalition accuracy is displayed below. Please, note that this <strong>mae.test.mean</strong> corresponds to the outer 3-fold crossvalidation, while the <strong>mae.test.mean</strong> above, corresponds to the inner 3-fold crossvalidation mae (computed during hyper-parameter tuning). It can be seen that, while hyper-parameter tuning was not able to reduce the feature space to just 1 attribute (it was reduced to 5 attributes), the test MAE obtained is reasonable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(error_knn_nntrf_tune<span class="op">$</span>aggr)
<span class="co">#&gt; mae.test.mean </span>
<span class="co">#&gt;   0.001877029</span></code></pre></div>
<div id="hyper-parameter-tuning-with-pca" class="section level2">
<h2>Hyper-parameter tuning with PCA</h2>
<p>In order to compare a supervised transformation method (<strong>nntrf</strong>) with an unsupervised one (PCA), it is very easy to do exactly the same pre-processing with PCA. In this case, the main hyper-parameters are <strong>k</strong> (number of KNN neighbors) and <strong>Pca.rank</strong> (the number of PCA components to be used, which would be the counterpart of <strong>size</strong>, the number of hidden neurons used by <strong>nntrf</strong>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knn_pca &lt;-<span class="st"> </span><span class="kw">cpoPca</span>(<span class="dt">center=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">TRUE</span>, <span class="dt">export=</span><span class="kw">c</span>(<span class="st">&quot;rank&quot;</span>)) <span class="op">%&gt;&gt;%</span><span class="st"> </span><span class="kw">makeLearner</span>(<span class="st">&quot;regr.fnn&quot;</span>)

ps_pca &lt;-<span class="st"> </span><span class="kw">makeParamSet</span>(<span class="kw">makeDiscreteParam</span>(<span class="st">&quot;k&quot;</span>, <span class="dt">values =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>),
                       <span class="kw">makeDiscreteParam</span>(<span class="st">&quot;pca.rank&quot;</span>, <span class="dt">values =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)
)

knn_pca_tune &lt;-<span class="st"> </span><span class="kw">makeTuneWrapper</span>(knn_pca, <span class="dt">resampling =</span> inner_desc, <span class="dt">par.set =</span> ps_pca, 
                                     <span class="dt">control =</span> control_grid, <span class="dt">measures =</span> <span class="kw">list</span>(mlr<span class="op">::</span>mae), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">0</span>)
<span class="co"># Please, note that in order to save time, results have been precomputed</span>

cached &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;error_knn_pca_tune_regression.rda&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;nntrf&quot;</span>)
<span class="cf">if</span>(<span class="kw">file.exists</span>(cached)){<span class="kw">load</span>(cached)} <span class="cf">else</span> {
error_knn_pca_tune &lt;-<span class="st"> </span><span class="kw">resample</span>(knn_pca_tune, sin_task, outer_inst, 
                               <span class="dt">measures =</span> <span class="kw">list</span>(mlr<span class="op">::</span>mae), 
                               <span class="dt">extract =</span> getTuneResult, <span class="dt">show.info =</span>  <span class="ot">FALSE</span>)
<span class="co">#save(error_knn_pca_tune, file=&quot;../inst/extdata/error_knn_pca_tune_regression.rda&quot;)</span>
}</code></pre></div>
<p>The cell below displays the results obtained by hyper-parameter tuning for the three external crossvalidation folds.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(error_knn_pca_tune<span class="op">$</span>extract)
<span class="co">#&gt; [[1]]</span>
<span class="co">#&gt; Tune result:</span>
<span class="co">#&gt; Op. pars: k=6; pca.rank=5</span>
<span class="co">#&gt; mae.test.mean=0.1064710</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[2]]</span>
<span class="co">#&gt; Tune result:</span>
<span class="co">#&gt; Op. pars: k=5; pca.rank=5</span>
<span class="co">#&gt; mae.test.mean=0.1057195</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[3]]</span>
<span class="co">#&gt; Tune result:</span>
<span class="co">#&gt; Op. pars: k=4; pca.rank=5</span>
<span class="co">#&gt; mae.test.mean=0.1068931</span></code></pre></div>
<p>It can be seen below that <strong>PCA</strong> obtains a much worse MAE than <strong>nntrf</strong>, if forced to use no more than 5 components.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(error_knn_pca_tune<span class="op">$</span>aggr)
<span class="co">#&gt; mae.test.mean </span>
<span class="co">#&gt;     0.1006023</span></code></pre></div>
</div>
<div id="hyper-parameter-tuning-with-just-knn" class="section level2">
<h2>Hyper-parameter tuning with just KNN</h2>
<p>For completeness sake, below are the results with, no pre-processing, just KNN (results are better than those of <strong>PCA</strong> with only 5 components) but worse than <strong>nntrf</strong>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ps_knn &lt;-<span class="st"> </span><span class="kw">makeParamSet</span>(<span class="kw">makeDiscreteParam</span>(<span class="st">&quot;k&quot;</span>, <span class="dt">values =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>))

knn_lrn &lt;-<span class="st"> </span><span class="kw">makeLearner</span>(<span class="st">&quot;regr.fnn&quot;</span>)
knn_tune &lt;-<span class="st"> </span><span class="kw">makeTuneWrapper</span>(knn_lrn, <span class="dt">resampling =</span> inner_desc, <span class="dt">par.set =</span> ps_knn, 
                                     <span class="dt">control =</span> control_grid, <span class="dt">measures =</span> <span class="kw">list</span>(mlr<span class="op">::</span>mae), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)

<span class="kw">set.seed</span>(<span class="dv">0</span>)
<span class="co"># Please, note that in order to save time, results have been precomputed</span>
cached &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata&quot;</span>, <span class="st">&quot;error_knn_tune_regression.rda&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;nntrf&quot;</span>)
<span class="cf">if</span>(<span class="kw">file.exists</span>(cached)){<span class="kw">load</span>(cached)} <span class="cf">else</span> {
error_knn_tune &lt;-<span class="st"> </span><span class="kw">resample</span>(knn_tune, sin_task, outer_inst, <span class="dt">measures =</span> <span class="kw">list</span>(mlr<span class="op">::</span>mae), 
                           <span class="dt">extract =</span> getTuneResult, <span class="dt">show.info =</span>  <span class="ot">FALSE</span>)
<span class="co">#save(error_knn_tune, file=&quot;../inst/extdata/error_knn_tune_regression.rda&quot;)</span>
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(error_knn_tune<span class="op">$</span>aggr)
<span class="co">#&gt; mae.test.mean </span>
<span class="co">#&gt;    0.07660643</span></code></pre></div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
